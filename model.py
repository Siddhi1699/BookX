# -*- coding: utf-8 -*-
"""samegenre.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1soirFMMZDK-xal_zxq1ZPP0R74AvWoFt
"""

from sklearn.metrics.pairwise import linear_kernel, cosine_similarity
from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import pickle
from surprise import Reader, Dataset, SVD
from surprise.model_selection import cross_validate
# from model import svd
import warnings
warnings.filterwarnings('ignore')

print("bb")

path1 = "books.csv"
path2 = "ratings.csv"
path3 = "book_tags.csv"
path4 = "tags.csv"

books = pd.read_csv(path1)
ratings = pd.read_csv(path2)
book_tags = pd.read_csv(path3)
tags = pd.read_csv(path4)

books['original_publication_year'] = books['original_publication_year'].fillna(
    -1).apply(lambda x: int(x) if x != -1 else -1)

ratings_rmv_duplicates = ratings.drop_duplicates()
unwanted_users = ratings_rmv_duplicates.groupby('user_id')['user_id'].count()
unwanted_users = unwanted_users[unwanted_users < 3]
unwanted_ratings = ratings_rmv_duplicates[ratings_rmv_duplicates.user_id.isin(
    unwanted_users.index)]
new_ratings = ratings_rmv_duplicates.drop(unwanted_ratings.index)

new_ratings['title'] = books.set_index(
    'id').title.loc[new_ratings.book_id].values

"""content based"""


books['authors'] = books['authors'].apply(
    lambda x: [str.lower(i.replace(" ", "")) for i in x])

print(books.columns.tolist())
header = ["InviteTime (Oracle)", "Orig Number", "Orig IP Address", "Dest Number"]



def get_genres(x):
    t = book_tags[book_tags.goodreads_book_id == x]
    return [i.lower().replace(" ", "") for i in tags.tag_name.loc[t.tag_id].values]


books['genres'] = books.book_id.apply(get_genres)

books['soup'] = books.apply(lambda x: ' '.join(
    [x['title']] + x['authors'] + x['genres']), axis=1)

count = CountVectorizer(analyzer='word', ngram_range=(
    1, 2), min_df=0, stop_words='english')
count_matrix = count.fit_transform(books['soup'])

cosine_sim = cosine_similarity(count_matrix, count_matrix)

indices = pd.Series(books.index, index=books['title'])
titles = books['title']


books.to_csv('ob.csv', columns =books.columns.tolist())
ratings.to_csv('or.csv', columns =ratings.columns.tolist())
book_tags.to_csv('obt.csv', columns =book_tags.columns.tolist())
tags.to_csv('ot.csv', columns =tags.columns.tolist())


print("beforeNY")


svd = SVD()


print("NY")
reader = Reader()
data = Dataset.load_from_df(
    new_ratings[['user_id', 'book_id', 'rating']], reader)

cross_validate(svd, data, measures=['RMSE', 'MAE'])

trainset = data.build_full_trainset()
svd.fit(trainset)


# save the model to disk
filename = 'model.sav'
pickle.dump(svd, open(filename, 'wb'))

loadedMod = pickle.load(open(filename, 'rb'))
# result = loaded_model.score(X_test, Y_test)


# knn_from_pickle = pickle.loads(saved_model)

# Use the loaded pickled model to make predictions
# knn_from_pickle.predict(X_test)


print("bb")
"""item based"""


def improved_hybrid(user_id, title, n=9):
    idx = indices[title]
    sim_scores = list(enumerate(cosine_sim[idx]))
    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)
    sim_scores = sim_scores[1:51]
    book_indices = [i[0] for i in sim_scores]

    df = books.iloc[book_indices][['book_id', 'image_url', 'authors', 'title',
                                   'ratings_count', 'average_rating', 'original_publication_year']]
    v = df['ratings_count']
    m = df['ratings_count'].quantile(0.60)
    R = df['average_rating']
    C = df['average_rating'].mean()
    df['weighted_rating'] = (R*v + C*m) / (v + m)

    df['est'] = df['book_id'].apply(lambda x: loadedMod.predict(user_id, x).est)

    df['score'] = (df['est'] + df['weighted_rating']) / 2
    df = df.sort_values('score', ascending=False)
    output = df[['book_id', 'image_url', 'authors', 'title',
                 'original_publication_year', 'ratings_count', 'average_rating', 'score']].head(n)

    return output.values.tolist()


print(improved_hybrid(4, "Twilight (Twilight, #1)"))


